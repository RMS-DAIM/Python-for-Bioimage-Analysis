{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning - Task A\n",
    "\n",
    "**Part of IAFIG-RMS *Python for Bioimage Analysis* Course.**\n",
    "\n",
    "*Mikolaj Kundegorski*\n",
    "\n",
    "2019-12-13\n",
    "\n",
    "In this task you will read in some toy data from an experiment and, using linear regression, try to predict the outcome for an 'unseen' or unknown measurement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  # We will use pandas DataFrames for storing features\n",
    "import numpy as np  # We will use NumPy arrays to store image data\n",
    "\n",
    "# Utils is a custom module written to simplify these tutorials\n",
    "# You do not need to understand these codes for this practical\n",
    "from utils.practice_data import generateNiceData\n",
    "\n",
    "# Generate a pandas Dataframe with some toy results\n",
    "# Each row (a cell) has four feature: A, B, C, Y\n",
    "# These could, for example, be length, intensity, etc.\n",
    "number_of_samples=100\n",
    "problem = generateNiceData(3,number_of_samples,noNoise=True)\n",
    "problem.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Task\n",
    "\n",
    "In one experiment we were able to measure four features: A, B, C, and Y. However, in our next experiment we could only measure A, B and C.\n",
    "\n",
    "Given these three features (A, B and C) we want to predict the value of feature Y.\n",
    "\n",
    "1. Let's start with a multivariate linear regression (assuming the relationship between our variables is simple).\n",
    "2. Advanced: Following see how the performance changes with and without noise in data\n",
    "3. Advanced: See how performance changes depending on size of the problem\n",
    "4. Advanced: Then try to provide non-linear features (i.e. assuming the relationship between our variables is complex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data from pandas series needs to be converted to familiar numpy arrays\n",
    "x = problem.loc[:,['A','B','C']].values\n",
    "y = problem.loc[:,'Y'].values\n",
    "\n",
    "print(x.shape, y.shape)  # check our array shapes make sense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task A.1 \n",
    "\n",
    "Read the documentation for function [sklearn.model_selection.train_test_split()](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html), start with the second example provided.\n",
    "\n",
    "In the cell below, complete the function call (by replacing all the `____`s) to split our dataset into 80% `x_train`/`y_train` (training) and 20% `x_test`/`y_test` (testing) subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection  # for trans_test_split function\n",
    "\n",
    "____, ____, ____, ____  = model_selection.train_test_split(____, ____, test_size=____, random_state=0)\n",
    "\n",
    "### REMOVE THESE LINES ###\n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(x, y, test_size=0.2, random_state=0)\n",
    "### REMOVE THESE LINES ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task A.2\n",
    "\n",
    " Look at the [Linear Regression class](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) documentation and examples. In the code below, we have initialised a Linear Regression model. Add the following lines of code:\n",
    "1. A line that 'fit's a model to our training data,\n",
    "2. A line that 'predict's the value of Y for our test data.\n",
    "\n",
    "What do the intercept and slope represent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model  # this submodule contains the 'LinearRegression' function\n",
    "\n",
    "mv_regression = linear_model.LinearRegression(normalize=True) #How would it perform without normalisation?\n",
    "\n",
    "# Fit regression model to feature data x_train and target y_train\n",
    "# ADD CODE HERE:\n",
    "### REMOVE THESE LINES ###\n",
    "mv_regression.fit(x_train,y_train)\n",
    "### REMOVE THESE LINES ###\n",
    "\n",
    "# Fill vector y_predict with estimations of target y_predict from data x_test\n",
    "# ADD CODE HERE:\n",
    "### REMOVE THESE LINES ###\n",
    "y_predict = mv_regression.predict(x_test)\n",
    "### REMOVE THESE LINES ###\n",
    "\n",
    "print(\"Intercept {}\".format(mv_regression.intercept_))\n",
    "print(\"Slope {}\".format(mv_regression.coef_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In machine learning we want to get an idea of how well our models fits our data (by comparing out prediction to our known testing data values), there are a variety of error metrics that can be used for this. Run the cell below to compare the 'True' or known values and the predicted values as well as three common error metrics. How do you interpret these numbers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "results = pd.DataFrame({'True value': y_test.flatten(), 'Predicted': y_predict.flatten()})\n",
    "print('Mean Absolute Error: {}'.format(metrics.mean_absolute_error(y_test, y_predict))  )\n",
    "print('Mean Squared Error: {}'.format(metrics.mean_squared_error(y_test, y_predict)) )\n",
    "print('Root Mean Squared Error: {}'.format(np.sqrt(metrics.mean_squared_error(y_test, y_predict))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numbers are all well and good, but often it's easier to understand our results when plotted visually. Run the cell below to compare the true and predicted values for our test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "f, axis = plt.subplots(1,1)  # create a figure with a single axis (subplot)\n",
    "\n",
    "axis.plot(y_test, y_test, '-')  # plot true vs true, i.e. the ideal case\n",
    "axis.scatter(y_test,y_predict)  # plot a scatter of the true value against the prediction value\n",
    "axis.set_ylabel('Predicted Value')\n",
    "axis.set_xlabel('True Value')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Task A.3\n",
    "\n",
    "In the cell below we have put all this code into a loop. Using `np.arange` we have defined a range of sample sizes. Run the loop to see how sample size affects the results.\n",
    "\n",
    "So far, these experiments have been magically noise free. Make `noNoise=False` and re-run the cell. How does noise affect the results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will store the error metrics for each sample size\n",
    "errors = pd.DataFrame(index=np.arange(20, 200, 20),columns=['MAE', 'MSE', 'RMS'])\n",
    "\n",
    "for number_of_samples in np.arange(20, 200, 20):\n",
    "    print('Running for {0} samples...'.format(number_of_samples))\n",
    "    problem = generateNiceData(3,number_of_samples,noNoise=True)\n",
    "    \n",
    "    #Data from pandas series needs to be converted to familiar numpy arrays\n",
    "    x = problem.loc[:,['A','B','C']].values\n",
    "    y = problem.loc[:,'Y'].values\n",
    "    \n",
    "    # Split test/train data\n",
    "    x_train, x_test, y_train, y_test = model_selection.train_test_split(x, y, test_size=0.2, random_state=0)\n",
    "    \n",
    "    # Initialise Linear Regression Model\n",
    "    mv_regression = linear_model.LinearRegression(normalize=True) #How would it perform without normalisation?\n",
    "    \n",
    "    # Fit regression model to feature data x_train and target y_train\n",
    "    mv_regression.fit(x_train,y_train)\n",
    "    \n",
    "    # Fill vector y_predict with estimations of target y_predict from data x_test\n",
    "    y_predict = mv_regression.predict(x_test)\n",
    "    \n",
    "    # Print Fit\n",
    "    print(\"Intercept {}\".format(mv_regression.intercept_))\n",
    "    print(\"Slope {}\".format(mv_regression.coef_))\n",
    "    \n",
    "    # Print Error Metrics\n",
    "    results = pd.DataFrame({'True value': y_test.flatten(), 'Predicted': y_predict.flatten()})\n",
    "    print('Mean Absolute Error: {}'.format(metrics.mean_absolute_error(y_test, y_predict)))\n",
    "    errors.loc[number_of_samples,'MAE'] = metrics.mean_absolute_error(y_test, y_predict)\n",
    "    print('Mean Squared Error: {}'.format(metrics.mean_squared_error(y_test, y_predict)))\n",
    "    errors.loc[number_of_samples,'MSE'] = metrics.mean_squared_error(y_test, y_predict)\n",
    "    print('Root Mean Squared Error: {}'.format(np.sqrt(metrics.mean_squared_error(y_test, y_predict))))\n",
    "    errors.loc[number_of_samples,'RMS'] = np.sqrt(metrics.mean_squared_error(y_test, y_predict))\n",
    "    \n",
    "    # Plot\n",
    "    f, axis = plt.subplots(1,1)  # create a figure with a single axis (subplot)\n",
    "    axis.plot(y_test, y_test, '-')  # plot true vs true, i.e. the ideal case\n",
    "    axis.scatter(y_test,y_predict)  # plot a scatter of the true value against the prediction value\n",
    "    axis.set_ylabel('Predicted Value')\n",
    "    axis.set_xlabel('True Value')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "# Show errors and create a quick plot\n",
    "display(errors)\n",
    "\n",
    "fErr, axErr = plt.subplots(1,1)  # create a figure with a single axis (subplot)\n",
    "\n",
    "errors.plot(ax=axErr)\n",
    "axErr.set_ylabel('Error Value')\n",
    "axErr.set_xlabel('Sample Size')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Task A.4\n",
    "\n",
    "Given your extensive knowledge of the property Y, you suspect that measurement B and C have a non-linear relation to Y. \n",
    "\n",
    "Modify the following cell to use function [np.power()](https://docs.scipy.org/doc/numpy/reference/generated/numpy.power.html) and [np.sin()](https://docs.scipy.org/doc/numpy/reference/generated/numpy.sin.html?highlight=sin#numpy.sin) to create additional non-linear features z_b and z_c. \n",
    "\n",
    "*Hint:* try different powers of `x_b`, from 2 to 8 to see when the fit is the closest. \n",
    "\n",
    "*Hint:* Apply sine function firectly to `x_c: z_c = np.sin(x_c)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_b = x_b\n",
    "z_c = x_c \n",
    "\n",
    "z_b = np.power(x_b,4)\n",
    "z_c = np.sin(x_c)\n",
    "\n",
    "#You can either add z-features to your existing measurements, or replace x_b and x_c with the non-linear features.\n",
    "x=np.concatenate((x_a,x_b,x_c,z_b,z_c),axis=1)\n",
    "x=np.concatenate((x_a,z_b,z_c),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Task A.5\n",
    "\n",
    "Copy the code from the cells above (task A.2) to try linear regression with your non-linear features. Do you need to change anything?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Task A.6\n",
    "\n",
    "Display the results on the test dataset by executing the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "results = pd.DataFrame({'True value': y_test.flatten(), 'Predicted': y_predict.flatten()})\n",
    "print('Mean Absolute Error: {}'.format(metrics.mean_absolute_error(y_test, y_predict))  )\n",
    "print('Mean Squared Error: {}'.format(metrics.mean_squared_error(y_test, y_predict)) )\n",
    "print('Root Mean Squared Error: {}'.format(np.sqrt(metrics.mean_squared_error(y_test, y_predict))))\n",
    "\n",
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "f, axis = plt.subplots(1,1)  # create a figure with a single axis (subplot)\n",
    "\n",
    "axis.plot(y_test, y_test, '-')  # plot true vs true, i.e. the ideal case\n",
    "axis.scatter(y_test,y_predict)  # plot a scatter of the true value against the prediction value\n",
    "axis.set_ylabel('Predicted Value')\n",
    "axis.set_xlabel('True Value')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
